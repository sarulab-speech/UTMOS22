{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb3f294-eb7a-4263-886b-cbbedc7dac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2fd77ad-1011-459b-a46f-f5e5f8e7b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import fairseq\n",
    "import torch\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d118c0cc-af15-49ec-8680-b87445b13c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mos_data(split):\n",
    "    mos_list_file = f'../data/phase1-ood/DATA/sets/{split}_mos_list.txt'\n",
    "    mos_data = {}\n",
    "    for line in open(mos_list_file):\n",
    "        elms = line.rstrip().split(',')\n",
    "        if len(elms) == 2:\n",
    "            file_id, mos = elms\n",
    "            mos = float(mos)\n",
    "            mos_data[file_id] = mos\n",
    "        else:\n",
    "            file_id = elms[0]\n",
    "            mos_data[file_id] = 0\n",
    "            \n",
    "    return mos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfd3208-ad88-4ba9-9e88-56e57860b69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mos_data = get_mos_data('train')\n",
    "len(train_mos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb1d82da-00fb-444a-bde0-c6c8546aadd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_mos_data = get_mos_data('val')\n",
    "len(val_mos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f14cf36-099d-4d1a-9b5f-220a6b85f434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_mos_data = get_mos_data('unlabeled')\n",
    "len(unlabeled_mos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66f0cdbc-6bd8-4348-95ce-ce5c663b4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = Path('../data/phase1-ood/DATA/wav/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfd7bf0-ed02-4d95-a8bd-3b31b4d79e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 16:34:00 | INFO | fairseq.tasks.hubert_pretraining | current directory is /home/koriyama/voicemos/220131ensemble/voiceMOS2022/notebooks\n",
      "2022-02-16 16:34:00 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/checkpoint/wnhsu/data/librivox', 'fine_tuning': False, 'labels': ['lyr9.km500'], 'label_dir': '/checkpoint/wnhsu/experiments/hubert/kmeans_20210121/km_dataset_librivox.model_iter_2.all', 'label_rate': 50, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2022-02-16 16:34:00 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50, 'extractor_mode': layer_norm, 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 768, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': True}\n"
     ]
    }
   ],
   "source": [
    "fairseq_base_model = '../fairseq/hubert_large_ll60k.pt'\n",
    "model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([fairseq_base_model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3fc3a0-afb8-423c-a8b2-2b24a72ba144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_model = model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445112fc-7a42-4ec3-b811-19daf88f9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_model.remove_pretraining_modules()\n",
    "ssl_model.to(device)\n",
    "ssl_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e28d6d-4430-4879-8a4d-973b4833da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean(wavpath):\n",
    "    with torch.no_grad():\n",
    "        wav = torchaudio.load(wavpath)[0]\n",
    "        res = ssl_model(wav.to(device), mask=False, features_only=True)\n",
    "        return res['x'].squeeze(0).mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780591e-8cdb-4665-a0c9-69fe012679a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46455624-7883-4f71-b1a2-ad9dd950344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('../out/utt_data/hubert_large')\n",
    "import os\n",
    "os.makedirs(out_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8d1737-dabb-42fb-b548-76024bc72e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fa3b31a6804b10b27dad52a91a12a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_vecs = []\n",
    "val_moss = []\n",
    "\n",
    "for key, mos in tqdm(sorted(val_mos_data.items())):\n",
    "    wavpath = wav_dir / key\n",
    "    vec = extract_mean(wavpath)\n",
    "    outpath = out_dir / (wavpath.stem + '.npy')\n",
    "    \n",
    "    vec = vec.detach().cpu().numpy()\n",
    "    np.save(outpath, vec)\n",
    "    \n",
    "    val_vecs.append(vec)\n",
    "    val_moss.append(mos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ff7f96-f474-466c-9579-0d6016093532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3565ccf976434088afa4117974bcc6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_vecs = []\n",
    "train_moss = []\n",
    "\n",
    "for key, mos in tqdm(sorted(train_mos_data.items())):\n",
    "    wavpath = wav_dir / key\n",
    "    vec = extract_mean(wavpath)\n",
    "    outpath = out_dir / (wavpath.stem + '.npy')\n",
    "    \n",
    "    vec = vec.detach().cpu().numpy()\n",
    "    np.save(outpath, vec)\n",
    "    \n",
    "    train_vecs.append(vec)\n",
    "    train_moss.append(mos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "899290fe-3b6a-4da7-9186-4a9f3205e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b268051970c423389fd52ccafd7139f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unlabeled_vecs = []\n",
    "unlabeled_moss = []\n",
    "\n",
    "for key, mos in tqdm(sorted(unlabeled_mos_data.items())):\n",
    "    wavpath = wav_dir / key\n",
    "    vec = extract_mean(wavpath)\n",
    "    outpath = out_dir / (wavpath.stem + '.npy')\n",
    "    \n",
    "    vec = vec.detach().cpu().numpy()\n",
    "    np.save(outpath, vec)\n",
    "    \n",
    "    unlabeled_vecs.append(vec)\n",
    "    unlabeled_moss.append(mos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79921351-f4d5-4795-aa38-0532122a30f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
